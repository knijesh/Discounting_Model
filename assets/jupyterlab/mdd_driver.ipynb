{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisite Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import project_lib\n",
    "import logging\n",
    "from project_lib import Project\n",
    "project_lib.utils.logger.get_logger().setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from clean_transform import *\n",
    "from cpd_utils import *\n",
    "from train_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data from various tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer        = pd.read_csv('/project_data/data_asset/customers.tsv', sep='\\t', na_values='?')\n",
    "discount_policy = pd.read_csv('/project_data/data_asset/discount_policy.tsv', sep='\\t', na_values='?')\n",
    "audit           = pd.read_csv('/project_data/data_asset/offer_audit.tsv', sep='\\t', na_values='?')\n",
    "offer           = pd.read_csv('/project_data/data_asset/offers.tsv', sep='\\t', na_values='?')\n",
    "oppo            = pd.read_csv('/project_data/data_asset/opportunities.tsv', sep='\\t', na_values='?')\n",
    "shipment        = pd.read_csv('/project_data/data_asset/shipment_profile.tsv', sep='\\t', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data from Oracle table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['SELECT * FROM HR.CUSTOMERS','SELECT * FROM HR.DISCOUNT_POLICY','SELECT * FROM HR.OFFER_AUDIT',\n",
    "         'SELECT * FROM HR.OPPORTUNITIES','SELECT * FROM HR.SHIPMENT_PROFILE','SELECT * FROM HR.OFFER']\n",
    "master_df = connect_to_oracle_db(query)\n",
    "customer        = col_handler(master_df['CUSTOMERS'])\n",
    "discount_policy = col_handler(master_df['DISCOUNT_POLICY'])\n",
    "audit           = col_handler(master_df['OFFER_AUDIT'])\n",
    "offer           = col_handler(master_df['OFFER'])\n",
    "oppo            = col_handler(master_df['OPPORTUNITIES'])\n",
    "shipment        = col_handler(master_df['SHIPMENT_PROFILE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Transform the data from various Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform(customer,discount_policy,audit,offer,oppo,shipment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Transformed file as a data asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Added as Data Assset\n"
     ]
    }
   ],
   "source": [
    "project = Project.access()\n",
    "add_file_path_as_data_asset(\"/project_data/data_asset/trn_dataset_transformed.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Added as Data Assset\n",
      "Evaluation Set /project_data/data_asset/eval_mdd.tsv Created\n"
     ]
    }
   ],
   "source": [
    "create_eval_set(path=\"/project_data/data_asset/trn_dataset_transformed.tsv\",outfile=\"/project_data/data_asset/eval_mdd.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Transformed Data to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-25 05:06:42,129]: ----- Retrieving Cleaned Training Data -----\n",
      "[2020-05-25 05:06:42,161]: ----- Training DHL CL -----\n",
      "[2020-05-25 05:06:42,164]: ----- Data Proprocessing: Checking E-Commerce -----\n",
      "[2020-05-25 05:06:42,172]: ----- Data Proprocessing: Getting Log Values -----\n",
      "[2020-05-25 05:06:42,199]: ----- Data Proprocessing: Getting Product Mix Ratios -----\n",
      "[2020-05-25 05:06:42,229]: ----- Data Proprocessing: Mapping Categorical Data -----\n",
      "[2020-05-25 05:06:42,241]: ----- Data Proprocessing: Pruning Data -----\n",
      "[2020-05-25 05:06:42,362]: ----- Define Training and Test Data -----\n",
      "[2020-05-25 05:06:42,370]: ----- Training 01_gradient_boosting -----\n",
      "[2020-05-25 05:06:42,372]: ----- Creating Model Pipelines -----\n",
      "[2020-05-25 05:06:42,374]: ----- Training Model Weights -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_gradient_boosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-25 05:07:18,936]: ----- Testing Trained Model -----\n",
      "[2020-05-25 05:07:18,986]: ----- Calculating Model Metrics -----\n",
      "[2020-05-25 05:07:18,992]: ----- Training 02_random_forest -----\n",
      "[2020-05-25 05:07:18,994]: ----- Creating Model Pipelines -----\n",
      "[2020-05-25 05:07:18,995]: ----- Training Model Weights -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RMSE: 8.018\n",
      "  MAE: 5.819\n",
      "  R2: 0.674\n",
      "  Explained_Variance: 0.674\n",
      "  score_test: 0.674\n",
      "  score_train: 0.737\n",
      "--- 01_gradient_boosting time ---\n",
      "--- 36.620174169540405 seconds ---\n",
      "02_random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-25 05:07:30,237]: ----- Testing Trained Model -----\n",
      "[2020-05-25 05:07:30,371]: ----- Calculating Model Metrics -----\n",
      "[2020-05-25 05:07:30,376]: ----- Training 03_neural_networks -----\n",
      "[2020-05-25 05:07:30,378]: ----- Creating Model Pipelines -----\n",
      "[2020-05-25 05:07:30,379]: ----- Training Model Weights -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RMSE: 8.082\n",
      "  MAE: 5.728\n",
      "  R2: 0.669\n",
      "  Explained_Variance: 0.669\n",
      "  score_test: 0.669\n",
      "  score_train: 0.822\n",
      "--- 02_random_forest time ---\n",
      "--- 11.383373737335205 seconds ---\n",
      "03_neural_networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-25 05:09:17,934]: ----- Testing Trained Model -----\n",
      "[2020-05-25 05:09:18,005]: ----- Calculating Model Metrics -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RMSE: 8.48\n",
      "  MAE: 6.126\n",
      "  R2: 0.635\n",
      "  Explained_Variance: 0.635\n",
      "  score_test: 0.635\n",
      "  score_train: 0.677\n",
      "--- 03_neural_networks time ---\n",
      "--- 107.63349890708923 seconds ---\n",
      "--- total DHL CL time ---\n",
      "--- 155.84831142425537 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model_lists = main(data_path=\"/project_data/data_asset/trn_dataset_transformed.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best performant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model,penul_model = fetch_best_performer(model_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model as an asset in the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_data_asset(model=final_model) #Best Model\n",
    "save_model_data_asset(model=penul_model) #Second Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_model_file_name = get_latest_model_file(path=\"/project_data/data_asset/*.model\")\n",
    "latest_model_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_id = get_asset_id(os.path.basename(latest_model_file_name))\n",
    "asset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the WML API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import os\n",
    "\n",
    "token = os.environ['USER_ACCESS_TOKEN']\n",
    "\n",
    "wml_credentials = {\n",
    "    \"token\": token,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n",
    "   \"version\": \"2.5.0\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)\n",
    "project_uid = os.environ['PROJECT_ID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Deployment Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space_meta = {\n",
    "#     client.spaces.ConfigurationMetaNames.NAME:\"DHL_Staging\"\n",
    "# }\n",
    "# spaces_details = client.spaces.store(space_meta)\n",
    "# spaces_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  --------------------  ------------------------\n",
      "GUID                                  NAME                  CREATED\n",
      "3b41a3c1-8671-4154-ac1e-58164a6550ff  DHL_Staging           2020-04-23T13:06:52.675Z\n",
      "f1d6281f-c594-43e6-a8dc-9be486d0b2b4  DHL_deployment_space  2020-04-17T04:09:08.541Z\n",
      "------------------------------------  --------------------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "client.spaces.list(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch GUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    instance_details = client.service_instance.get_details()\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['guid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3b41a3c1-8671-4154-ac1e-58164a6550ff'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client,\"DHL_Staging\")\n",
    "space_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set default Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote Data Assset to Deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_assets.create(\"eval_mdd.tsv\",\"/project_data/data_asset/eval_mdd.tsv\")\n",
    "client.data_assets.create(\"preprocess.py\",\"/home/wsuser/work/project_git_repo/dhl_ibm_cp4d/assets/jupyterlab/utils.py\")\n",
    "client.data_assets.create(\"config.py\",\"/home/wsuser/work/project_git_repo/dhl_ibm_cp4d/assets/jupyterlab/config.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promote Latest Model to Deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latest_model_file_name\n",
    "#client.data_assets.create(os.path.basename(latest_model_file_name),latest_model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------  ----------  -------  ------------------------------------\n",
      "NAME           ASSET_TYPE  SIZE     ASSET_ID\n",
      "eval_mdd.tsv   data_asset  324500   4eab2759-b47a-4d3c-aa6f-fbeaac9798cd\n",
      "MDD_v1.model   data_asset  4161337  a3f6e103-26c7-47a1-b4b8-61752680b188\n",
      "MDD_v2.model   data_asset  102801   702aea7b-ae8b-4dd1-b925-8f43aba1a760\n",
      "preprocess.py  data_asset  6977     2113e3a3-897f-4884-8b71-03fa6a054932\n",
      "config.py      data_asset  11043    20eb4969-ee06-46fd-84c1-863e14752cec\n",
      "-------------  ----------  -------  ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "client.set.default_space(space_uid)\n",
    "client.data_assets.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the deployment function parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.data_assets.get_details(\"702aea7b-ae8b-4dd1-b925-8f43aba1a760\")\n",
    "model_id = client.data_assets.get_uid(model_details)\n",
    "model_href = client.data_assets.get_href(model_details)\n",
    "\n",
    "\n",
    "data_details = client.data_assets.get_details(\"4eab2759-b47a-4d3c-aa6f-fbeaac9798cd\")\n",
    "data_id = client.data_assets.get_uid(data_details)\n",
    "\n",
    "\n",
    "script_details = client.data_assets.get_details(\"2113e3a3-897f-4884-8b71-03fa6a054932\")\n",
    "script_id = client.data_assets.get_uid(script_details)\n",
    "\n",
    "config_script_details = client.data_assets.get_details(\"20eb4969-ee06-46fd-84c1-863e14752cec\")\n",
    "config_script_id = client.data_assets.get_uid(config_script_details)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"wml_credentials\": wml_credentials,\n",
    "    \"project_uid\": project_uid,\n",
    "    \"space_uid\": space_uid,\n",
    "    \"mdd_model_id\": model_id,\n",
    "    \"data_details\":data_id,\n",
    "    \"preprocess_scripts\":script_id,\n",
    "    \"config_scripts\":config_script_id\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployable MDD Python Closure Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdd_deployment_function(params=params):\n",
    "    import subprocess\n",
    "    import sys,time\n",
    "    import pickle\n",
    "    from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "    \n",
    "    params['wml_credentials']['instance_id'] = 'openshift'\n",
    "    \n",
    "    sys.path.insert(0,'/home/wmlfuser/.local/lib/python3.6/site-packages/')\n",
    "    sys.path.insert(0, './')\n",
    "\n",
    "    \n",
    "    # Setup Client\n",
    "    client = WatsonMachineLearningAPIClient(params['wml_credentials'])\n",
    "    client.set.default_space(params['space_uid'])\n",
    "    \n",
    "    #Download Required Models and Files locally\n",
    "    client.data_assets.download(params['preprocess_scripts'],\"preprocess.py\")\n",
    "    client.data_assets.download(params['config_scripts'],\"config.py\")\n",
    "    client.data_assets.download(params['mdd_model_id'],\"mdd.model\")\n",
    "    #pro_data = pd.read_csv('/project_data/data_asset/eval_mdd.tsv', sep='\\t', na_values='?')\n",
    "    \n",
    "    \n",
    "    #Payload Preprocessing \n",
    "    \n",
    "    def payload_process(data):\n",
    "        import preprocess\n",
    "        import config\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        #Preprocessing of the Evaluation Input\n",
    "\n",
    "        data = data.drop(['weight'], axis=1, errors='ignore')\n",
    "\n",
    "        # ----- Some intial preprocessing calculations -----\n",
    "        data.new_potential_revenue.replace(0, np.nan, inplace = True)\n",
    "        data.published_revenue.replace(0, np.nan, inplace = True)\n",
    "        data.shipments.replace(0, np.nan, inplace = True)\n",
    "        data.wps.replace(0, np.nan, inplace = True)\n",
    "        data.insert(11,'weight',data['wps']*data['shipments'])\n",
    "        data[['weight',\n",
    "                'published_revenue',\n",
    "                'new_potential_revenue']] = data[['weight','published_revenue',\n",
    "                                            'new_potential_revenue']].astype(float)\n",
    "        data.rename(columns={\n",
    "                    'reason_for_lead'                :'REASONFORLEAD'\n",
    "                    ,'lead_source_type'                   :'LEADSOURCE'\n",
    "                    ,'industry_code'                     :'INDUSTRY'\n",
    "                    ,'primary_competitor'                     :'MAINCOMP'\n",
    "                    }, inplace=True)\n",
    "\n",
    "        label_col = \"discount\"\n",
    "        bin_col = ['ecomm']\n",
    "        cat_col = ['industry','product_cluster','loyalty_code','opportunity_type','reason_for_lead','lead_source_type','competitor']\n",
    "\n",
    "        num_col = [\n",
    "        'log_published_revenue', # log(published_revenue)\n",
    "        'log_published_revenue_sq', # (log(published_revenue))^2\n",
    "        'log_potential_revenue', # log(new_potential_revenue)\n",
    "        'log_offer_published_revenue', # log(offer_published_revenue)\n",
    "        'log_shipments', # log(shipments)\n",
    "        'log_wps', # log(wps)\n",
    "        'log_weight', # log(shipments x wps)\n",
    "        'PROD.MIX:DDEXPORT',\n",
    "        'PROD.MIX:DDIMPORT',\n",
    "        'PROD.MIX:TD3RD',\n",
    "        'PROD.MIX:DOMESTIC',\n",
    "        'PROD.MIX:TDEXPORT',\n",
    "        'PROD.MIX:TDIMPORT']\n",
    "\n",
    "        slice = data.loc[(data['organization_id'] == data['organization_id'].unique()[0])]\n",
    "        slice['physical_channel'] = slice.physical_channel.astype('str').replace(\".\",'')\n",
    "        slice = preprocess.preprocess(slice,label_col,bin_col,num_col,cat_col)\n",
    "        \n",
    "        return slice\n",
    " \n",
    "\n",
    "    def score(payload):\n",
    "        \n",
    "        import preprocess\n",
    "        import config\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import pickle\n",
    "        \n",
    "        field_values =[]\n",
    "              \n",
    "        try:\n",
    "            #Load the Saved Model\n",
    "            \n",
    "            with open('mdd.model','rb') as f:\n",
    "                final_mdd_model = pickle.load(f)\n",
    "                \n",
    "            #Decode a Dataframe from Payload Json\n",
    "\n",
    "            values = payload['input_data'][0]['values']\n",
    "            fields = payload['input_data'][0]['fields']\n",
    "            \n",
    "            data = pd.DataFrame(values,columns=fields)\n",
    "            data.replace('OPENSCALE','',inplace=True)\n",
    "            data.replace(99999,0,inplace = True)\n",
    "            \n",
    "            categorical_columns = ['industry_code','product_cluster','reason_for_lead','lead_source_type','primary_competitor','contactrole','physical_channel']\n",
    "            feature_columns = ['offer_id','organization_id','recommended_revenue','recommended_pid','recommended_pid_name','physical_channel','published_revenue','new_potential_revenue','shipments','wps', 'product_cluster', 'industry_code','contactrole','reason_for_lead', 'lead_source_type','primary_competitor']\n",
    "            non_numerical = ['recommended_pid_name','offer_id','organization_id'] + categorical_columns\n",
    "            numerical = [each for each in feature_columns if each not in non_numerical]\n",
    "            for each in numerical:\n",
    "                if not each =='shipments':\n",
    "                    data[each] = data[each].astype('float64')\n",
    "                else:\n",
    "                    data[each] = data[each].astype('int')\n",
    "                    \n",
    "            for each in non_numerical:\n",
    "                data[each] = data[each].astype('str')\n",
    "                \n",
    "            #data['recommended_pid'] = data['recommended_pid'].astype('str')\n",
    "                       \n",
    "            values = data.values.tolist()\n",
    "            \n",
    "            #Preprocess the raw data load before scoring\n",
    "            slice = payload_process(data)\n",
    "            \n",
    "            \n",
    "            X = slice\n",
    "            y = final_mdd_model.predict(slice)\n",
    "            \n",
    "            #return {'predictions':[{'results': list(y)}]}\n",
    "            \n",
    "        \n",
    "           \n",
    "            y = list(y)\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(y) :\n",
    "                values[i].append(y[i])\n",
    "                i +=1\n",
    "                    \n",
    "            return {'predictions':[{'fields':fields+['predictions'],'values': values}]}\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\"predictions\": [{\"error\" : repr(e)}]}\n",
    "        \n",
    "    return score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ------------------------------  ------------------------  ---------  ---------------\n",
      "GUID                                  NAME                            CREATED                   FRAMEWORK  TYPE\n",
      "caffe_frcnn                           caffe_frcnn                     2020-04-11T07:24:58.096Z  -          Python runtime\n",
      "caffe2_0.8                            caffe2_0.8                      2020-04-11T07:24:58.052Z  -          Python runtime\n",
      "theano_1.0                            theano_1.0                      2020-04-11T07:24:58.000Z  -          Python runtime\n",
      "do_12.9                               do_12.9                         2020-04-11T07:24:59.662Z  -          do runtime\n",
      "hybrid_0.2                            hybrid_0.2                      2020-04-11T07:24:59.464Z  -          hybrid runtime\n",
      "hybrid_0.1                            hybrid_0.1                      2020-04-11T07:24:59.446Z  -          hybrid runtime\n",
      "torch_lua52                           torch_lua52                     2020-04-11T07:24:58.247Z  -          lua runtime\n",
      "torch_luajit                          torch_luajit                    2020-04-11T07:24:58.227Z  -          lua runtime\n",
      "tensorflow_0.11-horovod               tensorflow_0.11-horovod         2020-04-11T07:24:59.054Z  -          native runtime\n",
      "caffe_1.0-ddl                         caffe_1.0-ddl                   2020-04-11T07:24:58.075Z  -          native runtime\n",
      "darknet_0                             darknet_0                       2020-04-11T07:24:58.027Z  -          native runtime\n",
      "pmml_4.3                              pmml_4.3                        2020-04-11T07:24:59.644Z  -          pmml runtime\n",
      "pmml_4.2.1                            pmml_4.2.1                      2020-04-11T07:24:59.626Z  -          pmml runtime\n",
      "pmml_4.2                              pmml_4.2                        2020-04-11T07:24:59.607Z  -          pmml runtime\n",
      "pmml_4.1                              pmml_4.1                        2020-04-11T07:24:59.588Z  -          pmml runtime\n",
      "pmml_4.0                              pmml_4.0                        2020-04-11T07:24:59.570Z  -          pmml runtime\n",
      "pmml_3.2                              pmml_3.2                        2020-04-11T07:24:59.552Z  -          pmml runtime\n",
      "pmml_3.1                              pmml_3.1                        2020-04-11T07:24:59.534Z  -          pmml runtime\n",
      "pmml_3.0                              pmml_3.0                        2020-04-11T07:24:59.516Z  -          pmml runtime\n",
      "eb808add-4c3e-4740-b621-d68769fecb62  MDD_DHL_Deployment_Function_V2  2020-04-24T12:17:30.002Z  -          python function\n",
      "7401fa51-522c-4441-a187-cc374d207cdd  MDD_DHL_Deployment_Function_V1  2020-04-23T13:30:01.002Z  -          python function\n",
      "ai-function_0.1-py3.6                 ai-function_0.1-py3.6           2020-04-11T07:24:59.499Z  -          python runtime\n",
      "ai-function_0.1-py3                   ai-function_0.1-py3             2020-04-11T07:24:59.482Z  -          python runtime\n",
      "xgboost_0.82-py3.6                    xgboost_0.82-py3.6              2020-04-11T07:24:59.428Z  -          python runtime\n",
      "xgboost_0.82-py3                      xgboost_0.82-py3                2020-04-11T07:24:59.410Z  -          python runtime\n",
      "xgboost_0.80-py3.6                    xgboost_0.80-py3.6              2020-04-11T07:24:59.392Z  -          python runtime\n",
      "xgboost_0.80-py3                      xgboost_0.80-py3                2020-04-11T07:24:59.373Z  -          python runtime\n",
      "xgboost_0.6-py3                       xgboost_0.6-py3                 2020-04-11T07:24:59.354Z  -          python runtime\n",
      "scikit-learn_0.20-py3.6               scikit-learn_0.20-py3.6         2020-04-11T07:24:59.279Z  -          python runtime\n",
      "scikit-learn_0.20-py3                 scikit-learn_0.20-py3           2020-04-11T07:24:59.260Z  -          python runtime\n",
      "scikit-learn_0.19-py3.6               scikit-learn_0.19-py3.6         2020-04-11T07:24:59.241Z  -          python runtime\n",
      "scikit-learn_0.19-py3                 scikit-learn_0.19-py3           2020-04-11T07:24:59.222Z  -          python runtime\n",
      "scikit-learn_0.17-py3                 scikit-learn_0.17-py3           2020-04-11T07:24:59.204Z  -          python runtime\n",
      "tensorflow_1.14-py3.6                 tensorflow_1.14-py3.6           2020-04-11T07:24:59.150Z  -          python runtime\n",
      "tensorflow_1.13-py3.6                 tensorflow_1.13-py3.6           2020-04-11T07:24:59.130Z  -          python runtime\n",
      "tensorflow_1.11-py3.6                 tensorflow_1.11-py3.6           2020-04-11T07:24:59.111Z  -          python runtime\n",
      "tensorflow_1.13-py3                   tensorflow_1.13-py3             2020-04-11T07:24:59.093Z  -          python runtime\n",
      "tensorflow_1.13-py2                   tensorflow_1.13-py2             2020-04-11T07:24:59.074Z  -          python runtime\n",
      "tensorflow_1.11-py3                   tensorflow_1.11-py3             2020-04-11T07:24:59.035Z  -          python runtime\n",
      "tensorflow_1.10-py3                   tensorflow_1.10-py3             2020-04-11T07:24:59.015Z  -          python runtime\n",
      "tensorflow_1.10-py2                   tensorflow_1.10-py2             2020-04-11T07:24:58.993Z  -          python runtime\n",
      "tensorflow_1.9-py3                    tensorflow_1.9-py3              2020-04-11T07:24:58.971Z  -          python runtime\n",
      "tensorflow_1.9-py2                    tensorflow_1.9-py2              2020-04-11T07:24:58.951Z  -          python runtime\n",
      "tensorflow_1.8-py3                    tensorflow_1.8-py3              2020-04-11T07:24:58.931Z  -          python runtime\n",
      "tensorflow_1.8-py2                    tensorflow_1.8-py2              2020-04-11T07:24:58.909Z  -          python runtime\n",
      "tensorflow_1.7-py3                    tensorflow_1.7-py3              2020-04-11T07:24:58.890Z  -          python runtime\n",
      "tensorflow_1.7-py2                    tensorflow_1.7-py2              2020-04-11T07:24:58.870Z  -          python runtime\n",
      "tensorflow_1.6-py3                    tensorflow_1.6-py3              2020-04-11T07:24:58.851Z  -          python runtime\n",
      "tensorflow_1.6-py2                    tensorflow_1.6-py2              2020-04-11T07:24:58.829Z  -          python runtime\n",
      "tensorflow_1.5-py2-ddl                tensorflow_1.5-py2-ddl          2020-04-11T07:24:58.808Z  -          python runtime\n",
      "------------------------------------  ------------------------------  ------------------------  ---------  ---------------\n",
      "Note: Only first 50 records were displayed. To display more use more specific list functions.\n"
     ]
    }
   ],
   "source": [
    "client.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Function in project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Metadata.\n",
    "client.set.default_project(project_id=project_uid)\n",
    "\n",
    "meta_props = {\n",
    "    client.repository.FunctionMetaNames.NAME: \"MDD_DHL_Function_V2\",\n",
    "    client.repository.FunctionMetaNames.RUNTIME_UID: \"ai-function_0.1-py3.6\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the function artifact for Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_artifact = client.repository.store_function(meta_props=meta_props, function=mdd_deployment_function)\n",
    "function_uid = client.repository.get_function_uid(function_artifact)\n",
    "print(\"Function UID = \" + function_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List out Functions in Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.list_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Deployment Function Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pro_data = pd.read_csv('/project_data/data_asset/eval_mdd.tsv', sep='\\t', na_values='?')\n",
    "#Encode\n",
    "temp = pd.read_csv('/project_data/data_asset/eval_mdd.tsv', sep='\\t', na_values='?')\n",
    "temp = temp.iloc[:5]\n",
    "fields = list(temp.columns)\n",
    "values = temp.values.tolist()\n",
    "request_data = {\"values\": values, \"fields\": fields}\n",
    "payload_data = {\"input_data\" : [request_data]}\n",
    "#print(payload_data) \n",
    "\n",
    "results = mdd_deployment_function()(payload_data)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Function in deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.repository.FunctionMetaNames.NAME: \"MDD_DHL_Deployment_Function_V2\",\n",
    "    client.repository.FunctionMetaNames.RUNTIME_UID: \"ai-function_0.1-py3.6\",\n",
    "    client.repository.FunctionMetaNames.SPACE_UID: space_uid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Function artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_artifact = client.repository.store_function(meta_props=meta_props, function=mdd_deployment_function)\n",
    "function_uid = client.repository.get_function_uid(function_artifact)\n",
    "print(\"Function UID = \" + function_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details about the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_details = client.repository.get_details(function_uid)\n",
    "from pprint import pprint\n",
    "pprint(function_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a list of all the functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.repository.list_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the MDD Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment metadata.\n",
    "deploy_meta = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"MDD_DHL_Deployment_Function_V2\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"mdd_deployment_function-deploy\",\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_details = client.deployments.create(function_uid, meta_props=deploy_meta)\n",
    "# Deployment UID.\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "print('Deployment uid = {}'.format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare scoring payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_data = prepare_scoring_payload(path='/project_data/data_asset/eval_mdd.tsv',no_of_records=2)\n",
    "\n",
    "fields = payload_data['input_data'][0]['fields']\n",
    "values = payload_data['input_data'][0]['values']\n",
    "\n",
    "job_payload = {\n",
    "    client.deployments.ScoringMetaNames.INPUT_DATA: [{\n",
    "        'fields': fields,\n",
    "        'values': values\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDD Model Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details = client.deployments.score(deployment_uid, job_payload)\n",
    "job_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
